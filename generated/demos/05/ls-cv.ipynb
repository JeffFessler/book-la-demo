{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# LS fitting with cross validation\n",
    "\n",
    "This example illustrates least squares (LS) polynomial fitting,\n",
    "with cross validation for selecting the polynomial degree,\n",
    "using the Julia language."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "Add the Julia packages used in this demo.\n",
    "Change `false` to `true` in the following code block\n",
    "if you are using any of the following packages for the first time."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "if false\n",
    "    import Pkg\n",
    "    Pkg.add([\n",
    "        \"InteractiveUtils\"\n",
    "        \"LaTeXStrings\"\n",
    "        \"MIRTjim\"\n",
    "        \"Plots\"\n",
    "        \"Polynomials\"\n",
    "        \"Random\"\n",
    "    ])\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tell Julia to use the following packages.\n",
    "Run `Pkg.add()` in the preceding code block first, if needed."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using InteractiveUtils: versioninfo\n",
    "using LaTeXStrings\n",
    "using LinearAlgebra: norm\n",
    "using MIRTjim: prompt\n",
    "using Plots: default, plot, plot!, scatter, scatter!, savefig\n",
    "using Polynomials: fit\n",
    "using Random: seed!\n",
    "default(); default(label=\"\", markerstrokecolor=:auto, widen=true, linewidth=2,\n",
    "    markersize = 6, tickfontsize=12, labelfontsize = 16, legendfontsize=14)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following line is helpful when running this jl-file as a script;\n",
    "this way it will prompt user to hit a key after each image is displayed."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "isinteractive() && prompt(:prompt);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simulated data from latent nonlinear function"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "f(x) = 0.5 * exp(1.8 * x) # nonlinear function\n",
    "\n",
    "seed!(0) # seed rng\n",
    "M = 12 # how many data points\n",
    "xm = sort(2*rand(M)) # M random sample locations\n",
    "σ = 0.5 # noise standard deviation\n",
    "z = σ * randn(M) # noise\n",
    "y = f.(xm) + z # noisy samples\n",
    "\n",
    "x0 = range(0, 2, 501) # fine sampling for showing curve\n",
    "xaxis = (L\"x\", (0,2), 0:2)\n",
    "yaxis = (L\"y\", (-2, 21), 0:4:20)\n",
    "p0 = scatter(xm, y, color=:black, label=\"y (noisy data), M = $M\"; xaxis, yaxis)\n",
    "plot!(x0, f.(x0), color=:blue, label=\"f(x) : latent function\", legend=:topleft)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "prompt()\n",
    "# savefig(p0, \"ls-cv-data.pdf\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Polynomial fitting\n",
    "\n",
    "Illustrate polynomial fits\n",
    "with degrees that are too low, just right, and too high."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "p1 = deepcopy(p0)\n",
    "degs = [1, 3, 9]\n",
    "for deg in degs\n",
    "    pol = fit(xm, y, deg)\n",
    "    plot!(p1, x0, pol.(x0), label = \"degree $deg\")\n",
    "end\n",
    "p1"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "prompt()\n",
    "# savefig(p1, \"ls-cv-fits.pdf\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Over-fitting to noisy data\n",
    "\n",
    "As the polynomial degree increases,\n",
    "the fit to the _noisy data_ improves.\n",
    "In contrast,\n",
    "the error w.r.t. the latent function $f$\n",
    "initially decreases,\n",
    "but then increases\n",
    "as the model over-fits to the noise."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "degs = 0:(M-1)\n",
    "fits = zeros(length(degs))\n",
    "accs = zeros(length(degs))\n",
    "for (id, deg) in enumerate(degs)\n",
    "    pol = fit(xm, y, deg)\n",
    "    fits[id] = norm(pol.(xm) - y) # fit to noisy data\n",
    "    accs[id] = norm(pol.(xm) - f.(xm)) # \"accuracy\" w.r.t. true function\n",
    "end\n",
    "pf = scatter(degs, fits; color=:red,\n",
    " xaxis = (\"degree\", extrema(degs), [0,3,11]),\n",
    " yaxis = (\"fits\", (0,8), ),\n",
    " label = (L\"‖ A_d \\hat{x}_d - y ‖_2\"),\n",
    ")\n",
    "scatter!(degs, accs;\n",
    " label = L\"‖ A_d \\hat{x}_d - f ‖_2\", marker=:uptri, color=:blue)\n",
    "plot!([extrema(degs)...], ones(2)*norm(f.(xm) - y),\n",
    " label = L\"‖ y - f ‖_2\", color=:green,)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "prompt()\n",
    "# savefig(pf, \"ls-cv-over.pdf\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Illustrate uncertainty\n",
    "\n",
    "Leave out one point at a time,\n",
    "fit the remaining $M-1$ points\n",
    "with a degree 8 polynomial,\n",
    "and predict the held-out point."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "colors = [:red, :orange, :yellow, :green, :cyan, :blue, :grey, :black]\n",
    "pols = Vector{Any}(undef, M)\n",
    "deg1 = 8\n",
    "p2 = plot(; xaxis, yaxis, title = \"degree = $deg1\", legend=:top)\n",
    "scatter!(p2, [-9], [-9]; marker=:square, color=:gray, label=\"prediction\")\n",
    "scatter!(p2, [-9], [-9]; marker=:circle, color=:black, label=\"data\")\n",
    "for m in 1:M\n",
    "    mm = (1:M)[[1:(m-1); (m+1):M]] # omit mth point\n",
    "    pols[m] = fit(xm[mm], y[mm], deg1)\n",
    "    color = colors[mod1(m, length(colors))]\n",
    "    plot!(p2, x0, pols[m].(x0); xaxis, yaxis, title = \"degree = $deg1\",\n",
    "     color,)\n",
    "    pred = pols[m](xm[m])\n",
    "    scatter!([xm[m]], [pred]; color, marker=:square)\n",
    "    scatter!([xm[m]], [y[m]]; color=:black)\n",
    "    plot!([1, 1]*xm[m], [y[m], pred]; color, line=:dash)\n",
    "end\n",
    "p2"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "prompt()\n",
    "# savefig(p2, \"ls-cv-uq.pdf\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cross validation (leave-one-out)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "degs = 1:8\n",
    "errs = zeros(length(degs), M)\n",
    "for (id, deg) in enumerate(degs)\n",
    "    for m in 1:M\n",
    "        mm = (1:M)[[1:(m-1); (m+1):M]]\n",
    "        pol = fit(xm[mm], y[mm], deg)\n",
    "        errs[id, m] = pol(xm[m]) - y[m]\n",
    "    end\n",
    "end\n",
    "cv_loss = sqrt.(sum(abs2, errs, dims=2))\n",
    "\n",
    "p3 = scatter(degs, cv_loss; legend = :top,\n",
    " xlabel = \"degree\",\n",
    " ylabel = \"error\",\n",
    " label = \"Cross-validation loss\",\n",
    ")\n",
    "scatter!(p3, degs, accs;\n",
    " label = L\"‖ A_d \\hat{x}_d - f ‖_2\", marker=:uptri, color=:blue)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "prompt()\n",
    "# savefig(p3, \"ls-cv-scat.pdf\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Estimate best polynomial degree\n",
    "using the cross validation loss.\n",
    "\n",
    "In this case the estimate is degree=4,\n",
    "which happens to match\n",
    "the best degree\n",
    "in terms of 2-norm fit to the latent function $f$."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "cv_degree = degs[argmin(cv_loss)]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "oracle_degree = degs[argmin(accs)]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Discrepancy principle\n",
    "\n",
    "An alternative to cross validation\n",
    "to see the hyper-parameter\n",
    "(polynomial degree in this case)\n",
    "that makes\n",
    "$$\n",
    "‖ A_d \\hat{x}_d - y ‖_2 ≈ σ \\sqrt{M}.\n",
    "$$\n",
    "This is called the\n",
    "[Discrepancy principle](https://www.sciencedirect.com/topics/engineering/discrepancy-principle)\n",
    "(DP)\n",
    "and its rationale is the fact that\n",
    "$$\n",
    "\\mathbb{E}[ ‖ y - f ‖_2^2 ]\n",
    "= \\mathbb{E}[ ‖ ε ‖_2^2 ]\n",
    "= σ^2 M.\n",
    "$$\n",
    "when $y = f + ε ∈ \\mathbb{R}^M$.\n",
    "\n",
    "The DP approach requires that\n",
    "the user know the standard deviation $σ$\n",
    "of the elements of the noise vector $ε$,\n",
    "whereas cross-validation does not require that knowledge.\n",
    "\n",
    "In this particular demo,\n",
    "the DP approach happens to pick the best degree=4,\n",
    "but in general DP is known to over-regularize."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "dp_degree = argmin(abs.(fits .- σ * sqrt(M)))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.6"
  },
  "kernelspec": {
   "name": "julia-1.11",
   "display_name": "Julia 1.11.6",
   "language": "julia"
  }
 },
 "nbformat": 4
}
