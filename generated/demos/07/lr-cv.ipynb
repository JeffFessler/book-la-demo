{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Low-Rank Selection via Cross Validation\n",
    "\n",
    "This example illustrates\n",
    "low-rank matrix approximation\n",
    "using cross-validation methods\n",
    "for rank parameter selection,\n",
    "using the Julia language.\n",
    "As discussed by\n",
    "[Owen & Perry, 2009](https://doi.org/10.1214/08-AOAS227),\n",
    "separate row or column hold-out\n",
    "is ineffective,\n",
    "whereas\n",
    "[Bi-Cross-Validation (BCV)](https://doi.org/10.1214/08-AOAS227)\n",
    "is more effective."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "Add the Julia packages used in this demo.\n",
    "Change `false` to `true` in the following code block\n",
    "if you are using any of the following packages for the first time."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "if false\n",
    "    import Pkg\n",
    "    Pkg.add([\n",
    "        \"InteractiveUtils\"\n",
    "        \"LaTeXStrings\"\n",
    "        \"LinearAlgebra\"\n",
    "        \"MIRTjim\"\n",
    "        \"Plots\"\n",
    "        \"Random\"\n",
    "    ])\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tell Julia to use the following packages.\n",
    "Run `Pkg.add()` in the preceding code block first, if needed."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using InteractiveUtils: versioninfo\n",
    "using LaTeXStrings\n",
    "using LinearAlgebra: svd, svdvals, Diagonal, norm, pinv\n",
    "using MIRTjim: prompt\n",
    "using Plots: default, gui, plot, plot!, scatter!, savefig\n",
    "using Random: seed!, randperm\n",
    "using Statistics: mean\n",
    "default(); default(label=\"\", markerstrokecolor=:auto, markersize=7,\n",
    "    labelfontsize=20, tickfontsize=16, legendfontsize=17, widen=true)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following line is helpful when running this jl-file as a script;\n",
    "this way it will prompt user to hit a key after each image is displayed."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "isinteractive() && prompt(:prompt);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Noiseless low-rank matrix and noisy data matrix"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "M, N = 100, 50 # problem size\n",
    "seed!(0)\n",
    "Ktrue = 5 # true rank (planted model)\n",
    "X = svd(randn(M,Ktrue)).U * Diagonal(1:Ktrue) * svd(randn(Ktrue,N)).Vt\n",
    "sig0 = 0.03 # noise standard deviation\n",
    "Y = X + sig0 * randn(size(X)) # noisy\n",
    "sy = svdvals(Y)\n",
    "sx = svdvals(X)\n",
    "sx[1:Ktrue]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "sy[1:Ktrue]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot singular values"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "ps = plot(xaxis = (L\"k\", (1,N), [1, Ktrue, N]), yaxis = (L\"σ\", (0,5.5), 0:5))\n",
    "scatter!(1:N, sy, color=:red, marker=:hexagon,\n",
    " label=L\"\\sigma_k(Y) \\ \\mathrm{noisy}\")\n",
    "scatter!(1:N, sx, color=:blue, label=L\"\\sigma_k(X) \\ \\mathrm{noiseless}\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "prompt()\n",
    "\n",
    "# savefig(ps, \"lr_sure1s.pdf\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Low-rank approximation with various ranks"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "(U, sy, V) = svd(Y)\n",
    "nrmse_K = zeros(N)\n",
    "nrmsd_K = zeros(N)\n",
    "nrmsd = (D) -> norm(D) / norm(Y) * 100\n",
    "nrmse = (D) -> norm(D) / norm(X) * 100\n",
    "for K in 1:N\n",
    "    Xh = U[:,1:K] * Diagonal(sy[1:K]) * V[:,1:K]'\n",
    "    nrmsd_K[K] = nrmsd(Xh - Y)\n",
    "    nrmse_K[K] = nrmse(Xh - X)\n",
    "end\n",
    "nrmsd_K = [nrmsd(0 .- Y); nrmsd_K]\n",
    "nrmse_K = [nrmse(0 .- X); nrmse_K]\n",
    "klist = 0:N;"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot normalized root mean-squared error/difference versus rank K"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "pk = plot( # legend=:outertop,\n",
    "    xaxis = (L\"K\", (1,N), [0, 2, Ktrue, N]),\n",
    "    yaxis = (\"'Error' [%]\", (0, 100), 0:20:100),\n",
    ")\n",
    "scatter!(klist, nrmse_K, color=:blue,\n",
    "    label=L\"\\mathrm{NRMSE\\ } ‖ \\! \\hat{X}_K - X \\ ‖_{\\mathrm{F}} / ‖X \\ ‖_{\\mathrm{F}} \\cdot 100\\%\",\n",
    ")\n",
    "scatter!(klist, nrmsd_K, color=:red, marker=:diamond,\n",
    "    label=L\"\\mathrm{NRMSD\\ } ‖ \\! \\hat{X}_K - Y \\ ‖_{\\mathrm{F}} / ‖Y \\ ‖_{\\mathrm{F}} \\cdot 100\\%\",\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "prompt()\n",
    "\n",
    "# savefig(pk, \"lr_sure1a.pdf\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bi-cross-validation code"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    bcv(Y::AbstractMatrix{<:Number}, ranks=1:10)\n",
    "Compute bi-cross-validation per\n",
    "https://doi.org/10.1214/08-AOAS227\n",
    "\"\"\"\n",
    "function bcv(Y::AbstractMatrix{<:Number}, ranks=1:10, fold::Int=2)\n",
    "    M, N = size(Y)\n",
    "    any(>(min(M,N)), ranks) && throw(\"bad ranks\")\n",
    "    any(<(0), ranks) && throw(\"bad ranks\")\n",
    "    H1 = M÷fold # hold-out rows\n",
    "    H2 = N÷fold # hold-out columns\n",
    "    perm1 = randperm(M)\n",
    "    hold1 = perm1[1:H1]\n",
    "    keep1 = perm1[(H1+1):M]\n",
    "    perm2 = randperm(N)\n",
    "    hold2 = perm2[1:H2]\n",
    "    keep2 = perm2[(H2+1):N]\n",
    "    A = Y[hold1,hold2]\n",
    "    B = Y[hold1,keep2]\n",
    "    C = Y[keep1,hold2]\n",
    "    D = Y[keep1,keep2]\n",
    "    U,s,V = svd(D)\n",
    "    error = zeros(length(ranks))\n",
    "    for (i, r) in enumerate(ranks)\n",
    "        Dr_pinv = V[:,1:r] * Diagonal(pinv.(s[1:r])) * U[:,1:r]'\n",
    "        error[i] = norm(A - B * Dr_pinv * C)\n",
    "    end\n",
    "    return error / norm(A) * 100\n",
    "end;"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Apply BCV to synthetic data\n",
    "\n",
    "In this example, (2×2)-fold BCV\n",
    "is minimized at the correct rank of 5."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "fold = 2\n",
    "ranks = 0:min(M,N)÷fold\n",
    "cv = bcv(Y, ranks, fold)\n",
    "scatter!(pk, ranks, cv, color=:green, marker=:star,\n",
    "    label=L\"\\mathrm{BCV}\",\n",
    ")\n",
    "i_bcv = argmin(cv)\n",
    "scatter!([ranks[i_bcv]], [cv[i_bcv]], color=:black, marker=:star, markersize=4,)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "prompt()\n",
    "\n",
    "# savefig(psk, \"lr_bcv1.pdf\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compare with row or column hold-out CV"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    function lr_cross_validation_by_column(Y, fold, n_components)\n",
    "\"\"\"\n",
    "function lr_cross_validation_by_column(\n",
    "    X::AbstractMatrix{<:Number},\n",
    "    fold::Int,\n",
    "    n_components::AbstractVector{<:Int},\n",
    ")\n",
    "\n",
    "    n_samples = size(X, 2) # Assuming columns are samples\n",
    "    fold_size = n_samples ÷ fold\n",
    "    errors = zeros(length(n_components), fold)\n",
    "\n",
    "    for fold_idx in 1:fold\n",
    "        test_indices = ((fold_idx - 1) * fold_size + 1):min(fold_idx * fold_size, n_samples)\n",
    "        train_indices = setdiff(1:n_samples, test_indices)\n",
    "\n",
    "        X_train = X[:, train_indices]\n",
    "        X_test = X[:, test_indices]\n",
    "\n",
    "        U, _, _ = svd(X_train) # \"PCA\" of training data\n",
    "\n",
    "        for (comp_idx, n_component) in enumerate(n_components)\n",
    "            Ur = U[:,1:n_component]\n",
    "            X_test_reconstructed = Ur * (Ur' * X_test)\n",
    "            errors[comp_idx, fold_idx] = # calculate reconstruction error\n",
    "                norm(X_test - X_test_reconstructed) / norm(X_test)\n",
    "        end\n",
    "    end\n",
    "    return errors * 100\n",
    "end;"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Apply elementary CV to same noisy data\n",
    "\n",
    "Holding out rows or columns\n",
    "leads to highly over-estimated ranks,\n",
    "as predicted in the literature.\n",
    "\n",
    "This is the approach recommended by GPT 4.1 (circa 2025-08),\n",
    "presumably because holding out individual data points\n",
    "is prevalent in machine learning."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "fold = 5\n",
    "Kmax = min(M,N)÷fold\n",
    "n_components = 0:Kmax\n",
    "errors_by_col = lr_cross_validation_by_column(Y, fold, n_components)\n",
    "error_means_by_col = vec(mean(errors_by_col, dims=2))\n",
    "i_col = argmin(error_means_by_col) # best based on minimum mean error\n",
    "\n",
    "errors_by_row = lr_cross_validation_by_column(Y', fold, n_components)\n",
    "error_means_by_row = vec(mean(errors_by_row, dims=2));\n",
    "i_row = argmin(error_means_by_row) # best based on minimum mean error\n",
    "\n",
    "optimal_k_col = n_components[i_col]\n",
    "optimal_k_row = n_components[i_row]\n",
    "\n",
    "pcv = plot(\n",
    " xlims=(0,10),\n",
    " xticks=[0, 1, 5, 10],\n",
    " ylims=(0,100),\n",
    " widen = true,\n",
    " xlabel = \"rank\",\n",
    " ylabel = \"NRMSD\",\n",
    ")\n",
    "scatter!(n_components, error_means_by_col, label=\"by column\")\n",
    "scatter!(n_components, error_means_by_row, label=\"by row\", marker=:x)\n",
    "scatter!([n_components[i_col]], [error_means_by_col[i_col]],\n",
    " color=:black, marker=:circle, markersize=4, )\n",
    "scatter!([n_components[i_row]], [error_means_by_row[i_row]],\n",
    " color=:black, marker=:x, markersize=4, )"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.6"
  },
  "kernelspec": {
   "name": "julia-1.11",
   "display_name": "Julia 1.11.6",
   "language": "julia"
  }
 },
 "nbformat": 4
}
