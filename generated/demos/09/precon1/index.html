<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Preconditioning · Demos</title><meta name="title" content="Preconditioning · Demos"/><meta property="og:title" content="Preconditioning · Demos"/><meta property="twitter:title" content="Preconditioning · Demos"/><meta name="description" content="Documentation for Demos."/><meta property="og:description" content="Documentation for Demos."/><meta property="twitter:description" content="Documentation for Demos."/><meta property="og:url" content="https://JeffFessler.github.io/book-la-demo/stable/generated/demos/09/precon1/"/><meta property="twitter:url" content="https://JeffFessler.github.io/book-la-demo/stable/generated/demos/09/precon1/"/><link rel="canonical" href="https://JeffFessler.github.io/book-la-demo/stable/generated/demos/09/precon1/"/><script data-outdated-warner src="../../../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../../../assets/documenter.js"></script><script src="../../../../search_index.js"></script><script src="../../../../siteinfo.js"></script><script src="../../../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../../../assets/themeswap.js"></script><link href="../../../../assets/custom.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../../../"><img src="../../../../assets/logo.png" alt="Demos logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../../../">Demos</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../../../">Home</a></li><li><span class="tocitem">01 Tutorials</span><ul><li><a class="tocitem" href="../../01/1-intro/">Tutorial: Julia Overview</a></li><li><a class="tocitem" href="../../01/2-vector/">Tutorial: Vectors in Julia</a></li></ul></li><li><span class="tocitem">02 Matrix</span><ul><li><a class="tocitem" href="../../02/conv-mat/">Convolution matrix</a></li><li><a class="tocitem" href="../../02/dot/">Vector dot product</a></li><li><a class="tocitem" href="../../02/gauss2d/">2d heatmap</a></li><li><a class="tocitem" href="../../02/mul-mat-vec/">Matrix-vector product</a></li><li><a class="tocitem" href="../../02/outer/">Vector outer product</a></li></ul></li><li><span class="tocitem">04 Subspaces</span><ul><li><a class="tocitem" href="../../04/svd-diff/">SVD of finite differences</a></li></ul></li><li><span class="tocitem">05 LS</span><ul><li><a class="tocitem" href="../../05/frame-cycle/">Wavelet frame denoising</a></li><li><a class="tocitem" href="../../05/ls-cost1/">LS cost functions</a></li><li><a class="tocitem" href="../../05/ls-cv/">LS fitting with cross validation</a></li><li><a class="tocitem" href="../../05/ls-fit1/">LS fitting</a></li><li><a class="tocitem" href="../../05/ls-lift/">LS lifting</a></li><li><a class="tocitem" href="../../05/sat-regress/">Linear regression and SAT scores</a></li></ul></li><li><span class="tocitem">06 Norm</span><ul><li><a class="tocitem" href="../../06/procrustes/">Procrustes method</a></li><li><a class="tocitem" href="../../06/robust-regress/">Robust regression</a></li></ul></li><li><span class="tocitem">07 Low-Rank</span><ul><li><a class="tocitem" href="../../07/lr-cv/">Low-Rank Selection via Cross Validation</a></li><li><a class="tocitem" href="../../07/lr-sure/">Low-Rank SURE</a></li><li><a class="tocitem" href="../../07/pca/">PCA</a></li><li><a class="tocitem" href="../../07/photometric3/">Photometric stereo</a></li><li><a class="tocitem" href="../../07/rank1/">Rank-1 approximation</a></li><li><a class="tocitem" href="../../07/source-local/">Source localization</a></li></ul></li><li><span class="tocitem">08 Special</span><ul><li><a class="tocitem" href="../../08/eigmap/">Laplacian eigenmaps</a></li><li><a class="tocitem" href="../../08/kron-sum-inv/">Kronecker sum of circulant</a></li><li><a class="tocitem" href="../../08/spectral-cluster/">Spectral clustering</a></li><li><a class="tocitem" href="../../08/ssc/">Sparse spectral clustering (SSC)</a></li></ul></li><li><span class="tocitem">09 Optimize</span><ul><li><a class="tocitem" href="../class01/">Binary classification</a></li><li><a class="tocitem" href="../logistic1/">Logistic regression</a></li><li class="is-active"><a class="tocitem" href>Preconditioning</a><ul class="internal"><li><a class="tocitem" href="#Setup"><span>Setup</span></a></li><li><a class="tocitem" href="#Background"><span>Background</span></a></li><li><a class="tocitem" href="#Setup-2"><span>Setup</span></a></li><li><a class="tocitem" href="#Gradient-Descent"><span>Gradient Descent</span></a></li><li><a class="tocitem" href="#Preconditioned-Gradient-Descent"><span>Preconditioned Gradient Descent</span></a></li><li><a class="tocitem" href="#Clicker-Question"><span>Clicker Question</span></a></li><li><a class="tocitem" href="#Ideal-Preconditioner"><span>Ideal Preconditioner</span></a></li><li><a class="tocitem" href="#Diagonal-Preconditioner"><span>Diagonal Preconditioner</span></a></li></ul></li></ul></li><li><span class="tocitem">10 Complete</span><ul><li><a class="tocitem" href="../../10/foreback/">Video foreground/background separation</a></li><li><a class="tocitem" href="../../10/lrmc-m/">Low-rank matrix completion: AltMin, ISTA, FISTA</a></li><li><a class="tocitem" href="../../10/lrmc3/">Low-rank matrix completion: ADMM</a></li><li><a class="tocitem" href="../../10/nmf/">Non-negative matrix factorization</a></li></ul></li><li><span class="tocitem">11 Neural nets</span><ul><li><a class="tocitem" href="../../11/ring3/">Classification with MLP</a></li></ul></li><li><span class="tocitem">12 RMT</span><ul><li><a class="tocitem" href="../../12/complete1/">RMT and matrix completion</a></li><li><a class="tocitem" href="../../12/gauss1/">Random matrix theory and rank-1 signal + noise</a></li><li><a class="tocitem" href="../../12/outlier1/">RMT and outliers</a></li><li><a class="tocitem" href="../../12/round1/">Roundoff errors and rank</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">09 Optimize</a></li><li class="is-active"><a href>Preconditioning</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Preconditioning</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JeffFessler/book-la-demo" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JeffFessler/book-la-demo/blob/main/docs/lit/demos/09/precon1.jl" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="precon1"><a class="docs-heading-anchor" href="#precon1">Preconditioning</a><a id="precon1-1"></a><a class="docs-heading-anchor-permalink" href="#precon1" title="Permalink"></a></h1><p>This example illustrates the effects of preconditioning matrices for gradient descent (GD) for least squares (LS) problems, using the Julia language.</p><ul><li>2019-11-19 Created by Steven Whitaker</li><li>2023-05-30 Julia 1.9 by Jeff Fessler</li></ul><p>This page comes from a single Julia file: <a href="https://github.com/JeffFessler/book-la-demo/blob/main/docs/lit/demos/09/precon1.jl"><code>precon1.jl</code></a>.</p><p>You can access the source code for such Julia documentation using the &#39;Edit on GitHub&#39; link in the top right. You can view the corresponding notebook in <a href="https://nbviewer.org/">nbviewer</a> here: <a href="https://nbviewer.org/github/JeffFessler/book-la-demo/tree/gh-pages/generated/demos/09/precon1.ipynb"><code>precon1.ipynb</code></a>, or open it in <a href="https://mybinder.org/">binder</a> here: <a href="https://mybinder.org/v2/gh/JeffFessler/book-la-demo/gh-pages?filepath=generated/demos/09/precon1.ipynb"><code>precon1.ipynb</code></a>.</p><h2 id="Setup"><a class="docs-heading-anchor" href="#Setup">Setup</a><a id="Setup-1"></a><a class="docs-heading-anchor-permalink" href="#Setup" title="Permalink"></a></h2><p>Add the Julia packages used in this demo. Change <code>false</code> to <code>true</code> in the following code block if you are using any of the following packages for the first time.</p><pre><code class="language-julia hljs">if false
    import Pkg
    Pkg.add([
        &quot;InteractiveUtils&quot;
        &quot;LaTeXStrings&quot;
        &quot;LinearAlgebra&quot;
        &quot;MIRTjim&quot;
        &quot;Plots&quot;
        &quot;Random&quot;
    ])
end</code></pre><p>Tell Julia to use the following packages. Run <code>Pkg.add()</code> in the preceding code block first, if needed.</p><pre><code class="language-julia hljs">using InteractiveUtils: versioninfo
using LaTeXStrings
using LinearAlgebra: svd, norm, svdvals, eigvals, Diagonal, I
using MIRTjim: prompt
using Plots: contour, default, gui, plot, plot!, savefig, scatter!
using Random: seed!
default(); default(markerstrokecolor=:auto, label = &quot;&quot;, markersize=6,
 tickfontsize=12, labelfontsize=18, legendfontsize=18)</code></pre><p>The following line is helpful when running this jl-file as a script; this way it will prompt user to hit a key after each image is displayed.</p><pre><code class="language-julia hljs">isinteractive() &amp;&amp; prompt(:prompt);</code></pre><h2 id="Background"><a class="docs-heading-anchor" href="#Background">Background</a><a id="Background-1"></a><a class="docs-heading-anchor-permalink" href="#Background" title="Permalink"></a></h2><p>The cost function to minimize for least squares problems is <span>$f(x) = \frac{1}{2} ‖ A x - y ‖_2^2,$</span> and its gradient is <span>$∇ f(x) = A&#39; (A x - y).$</span></p><p>Preconditioned GD with positive definite preconditioner <span>$P$</span> has the following update:</p><p><span>$x_{k+1} = x_{k} - P A&#39; (A x_k - y).$</span></p><p>For preconditioned GD to converge from any starting point, the following must be satisfied:</p><p><span>$-1 &lt; \mathrm{eig}\{G\} &lt; 1$</span>, where <span>$G = I - P^{1/2} A&#39; A P^{1/2}.$</span></p><p>Furthermore, the closer the eigenvalues of <span>$G$</span> are to zero, the faster preconditioned GD converges.</p><h2 id="Setup-2"><a class="docs-heading-anchor" href="#Setup-2">Setup</a><a class="docs-heading-anchor-permalink" href="#Setup-2" title="Permalink"></a></h2><p>This notebook creates a matrix <span>$A \in \mathbb{R}^{3 \times 2}$</span> with specified singular values, and uses <span>$y = 0 \in \mathbb{R}^3$</span> for simplicity of plots.</p><p>Create random <code>3 × 2</code> matrix with singular values 10 and 3</p><pre><code class="language-julia hljs">seed!(0)
(U, _, V) = svd(randn(3,2))
A = U * [10 0; 0 3] * V&#39;;</code></pre><p>Set up LS cost function and its gradient</p><pre><code class="language-julia hljs">f(x) = 0.5 * norm(A * x)^2
∇f(x) = A&#39; * (A * x)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">∇f (generic function with 1 method)</code></pre><p>Function for generating the matrix <span>$G$</span> from a given preconditioner matrix</p><pre><code class="language-julia hljs">G(sqrtP) = I - sqrtP&#39; * (A&#39; * A) * sqrtP;</code></pre><h2 id="Gradient-Descent"><a class="docs-heading-anchor" href="#Gradient-Descent">Gradient Descent</a><a id="Gradient-Descent-1"></a><a class="docs-heading-anchor-permalink" href="#Gradient-Descent" title="Permalink"></a></h2><p>First consider regular GD, i.e., preconditioned GD with <span>$P = \alpha I,$</span> where <span>$α$</span> is the step size.</p><p>We use the optimal step size <span>$α = \frac{2}{σ_1^2(A) + σ_N^2(A)}.$</span></p><p>Pick step size (preconditioner <span>$P = αI$</span>)</p><pre><code class="language-julia hljs">α = 2 / (sum(svdvals(A&#39; * A)[[1, end]])) # Optimal step size
eigvals(G(sqrt(α))) # Eigenvalues of G govern rate of convergence</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2-element Vector{Float64}:
 -0.8348623853211002
  0.8348623853211012</code></pre><p>Plot cost function</p><pre><code class="language-julia hljs">x1 = -10:0.1:10
x2 = -10:0.1:10
xidx = [[x1[i], x2[j]] for i in 1:length(x1), j in 1:length(x2)]
scale = 1/1000 # simplify clim
pu = contour(x1, x2, scale * f.(xidx)&#39;, annotate = (1, 6, &quot;Unpreconditioned&quot;),
 xaxis = (L&quot;x_1&quot;, (-1,1).*10),
 yaxis = (L&quot;x_2&quot;, (-1,1).*10),
 size = (500,400),
);

x0 = [5.0, -8.0] # initial guess
scatter!(pu, [x0[1]], [x0[2]], color=:green, label = L&quot;x_0&quot;);</code></pre><p>Run GD</p><pre><code class="language-julia hljs">niter = 100
x = Vector{Vector{Float64}}(undef, niter + 1)
x[1] = x0
for k in 1:niter
    x[k+1] = x[k] - α * ∇f(x[k])
end</code></pre><p>Display iterates</p><pre><code class="language-julia hljs">plot!(pu, [x[k][1] for k in 1:niter], [x[k][2] for k in 1:niter],
    marker=:star, color=:blue, label = L&quot;x_k&quot;);</code></pre><p>Mark the minimum of the cost function</p><pre><code class="language-julia hljs">scatter!(pu, [0], [0], label = L&quot;\hat{x}&quot;, color=:red,
    aspect_ratio = :equal, marker = :x)

# savefig(pu, &quot;precon1-pu.pdf&quot;)</code></pre><img src="17a290a0.svg" alt="Example block output"/><pre><code class="language-julia hljs">prompt()</code></pre><p>The contours of our cost function <span>$f(x)$</span> are ellipses. The ratio of the singular values of <span>$A$</span> determines the eccentricity, or how oblong (non-circular) the ellipse is. In our case, the singular values are 10 and 3, so the major axis of the contour ellipse is 10/3 as long as the minor axis.</p><h2 id="Preconditioned-Gradient-Descent"><a class="docs-heading-anchor" href="#Preconditioned-Gradient-Descent">Preconditioned Gradient Descent</a><a id="Preconditioned-Gradient-Descent-1"></a><a class="docs-heading-anchor-permalink" href="#Preconditioned-Gradient-Descent" title="Permalink"></a></h2><p>Now let&#39;s see how adding a preconditioner matrix changes things.</p><p>Manipulating the preconditioned GD step for LS problems leads to the following update:</p><p><span>$x_{k+1} = x_k - P A&#39; (A x_k - y)$</span></p><p><span>$P^{-1/2} x_{k+1} = P^{-1/2} x_k - P^{1/2} A&#39; (A x_k - y)$</span></p><p><span>$P^{-1/2} x_{k+1} = P^{-1/2} x_k - P^{1/2} A&#39; (A P^{1/2} P^{-1/2} x_k - y)$</span></p><p><span>$z_{k+1} = z_k - P^{1/2} A&#39; (A P^{1/2} z_k - y)$</span>, where <span>$z_k = P^{-1/2} x_k$</span></p><p><span>$z_{k+1} = z_k - \tilde{A}&#39; (\tilde{A} z_k - y)$</span>, where <span>$\tilde{A} = A P^{1/2}$</span>, and we used the fact that <span>$P^{1/2}$</span> is Hermitian symmetric.</p><p>This last equation is the normal (not preconditioned) GD step (with step size 1) for a LS problem with cost function <span>$\tilde{f}(z) = \frac{1}{2} ‖ \tilde{A} z - y ‖_2^2$</span>.</p><h2 id="Clicker-Question"><a class="docs-heading-anchor" href="#Clicker-Question">Clicker Question</a><a id="Clicker-Question-1"></a><a class="docs-heading-anchor-permalink" href="#Clicker-Question" title="Permalink"></a></h2><p>The preconditioned LS cost function <span>$\tilde{f}$</span> relates to the non-preconditioned LS cost function <span>$f$</span> via the relation <span>$\tilde{f}(z) = f(g(z))$</span> for what function <span>$g$</span>?</p><ul><li>A. <span>$g(z) = P^{-1/2} z$</span></li><li>B. <span>$g(z) = P^{1/2} z$</span></li><li>C. <span>$g(z) = z$</span></li><li>D. <span>$g(z) = \tilde{A} z$</span></li><li>E. <span>$g(z) = \tilde{A}&#39; z$</span></li></ul><h2 id="Ideal-Preconditioner"><a class="docs-heading-anchor" href="#Ideal-Preconditioner">Ideal Preconditioner</a><a id="Ideal-Preconditioner-1"></a><a class="docs-heading-anchor-permalink" href="#Ideal-Preconditioner" title="Permalink"></a></h2><p>We first consider the ideal preconditioner <span>$P = (A&#39; A)^{-1}$</span>.</p><p>Compute ideal preconditioner</p><pre><code class="language-julia hljs">sqrtPideal = sqrt(inv(A&#39; * A))
eigvals(G(sqrtPideal))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2-element Vector{Float64}:
 4.440892098500626e-16
 5.551115123125783e-16</code></pre><p>Set up preconditioned cost function and its gradient</p><pre><code class="language-julia hljs">f̃ideal(z) = f(sqrtPideal * z)
∇f̃ideal(z) = sqrtPideal&#39; * ∇f(sqrtPideal * z);</code></pre><p>Plot preconditioned cost function</p><pre><code class="language-julia hljs">z1 = -40:40
z2 = -40:40
zidx = [[z1[i], z2[j]] for i in 1:length(z1), j in 1:length(z2)]
scale = 1/250 # simplify clim
ph = contour(z1, z2, scale * f̃ideal.(zidx)&#39;,
 annotate = (9, 24, &quot;Ideal preconditioner&quot;),
 xaxis = (L&quot;z_1&quot;, (-1,1).*40),
 yaxis = (L&quot;z_2&quot;, (-1,1).*40),
 size = (500,400),
);</code></pre><p>Transform initial x guess into z coordinates and plot</p><pre><code class="language-julia hljs">z0 = sqrtPideal \ x0
scatter!(ph, [z0[1]], [z0[2]], color=:green, label = L&quot;z_0&quot;);</code></pre><p>Run GD</p><pre><code class="language-julia hljs">zk = z0 - ∇f̃ideal(z0)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2-element Vector{Float64}:
  2.1316282072803006e-14
 -7.105427357601002e-15</code></pre><p>Display iterates</p><pre><code class="language-julia hljs">plot!(ph, [z0[1],zk[1]], [z0[2],zk[2]], marker=:star, color=:blue, label = L&quot;z_k&quot;);</code></pre><p>Mark the minimum of the preconditioned cost function</p><pre><code class="language-julia hljs">scatter!(ph, [0], [0], label = L&quot;\hat{z}&quot;, color=:red,
    aspect_ratio = :equal, marker = :x)

# savefig(ph, &quot;precon1-ph.pdf&quot;)</code></pre><img src="edf317f9.svg" alt="Example block output"/><pre><code class="language-julia hljs">prompt()</code></pre><p>Using the ideal preconditioner caused a coordinate change in which the contours of our cost function are circles. In this new coordinate system, the negative gradient of our cost function points towards the minimizer. Furthermore, with the ideal preconditioner GD converged in just one step, which agrees with the fact that the eigenvalues of <span>$G$</span> for this preconditioner are 0 (ignoring numerical precision issues). Unfortunately, computing the ideal preconditioner is expensive.</p><h2 id="Diagonal-Preconditioner"><a class="docs-heading-anchor" href="#Diagonal-Preconditioner">Diagonal Preconditioner</a><a id="Diagonal-Preconditioner-1"></a><a class="docs-heading-anchor-permalink" href="#Diagonal-Preconditioner" title="Permalink"></a></h2><p>A less expensive preconditioner is the diagonal preconditioner <span>$P = \alpha \; \mathrm{diag}\{|A&#39; A| 1_N\}^{-1}$</span>. For convergence, we must have <span>$0 &lt; \alpha &lt; 2$</span>. We use an empirically chosen value for <span>$α$</span> in that range.</p><p>Pick step size and compute diagonal preconditioner</p><pre><code class="language-julia hljs">α = 1.71 # Chosen empirically
sqrtPdiag = sqrt(α * inv(Diagonal(abs.(A&#39; * A) * ones(size(A, 2)))))
eigvals(G(sqrtPdiag))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2-element Vector{Float64}:
 -0.7100000000000003
  0.620164835067933</code></pre><p>Set up preconditioned cost function and its gradient</p><pre><code class="language-julia hljs">f̃diag(z) = f(sqrtPdiag * z)
∇f̃diag(z) = sqrtPdiag&#39; * ∇f(sqrtPdiag * z);</code></pre><p>Plot preconditioned cost function</p><pre><code class="language-julia hljs">z1 = -50:50
z2 = -50:50
zidx = [[z1[i], z2[j]] for i in 1:length(z1), j in 1:length(z2)]
scale = 1/500 # simplify clim
pd = contour(z1, z2, scale * f̃diag.(zidx)&#39;,
 annotate = (12, 30, &quot;Diagonal preconditioner&quot;),
 xaxis = (L&quot;z_1&quot;, (-1,1).*50),
 yaxis = (L&quot;z_2&quot;, (-1,1).*50),
 size = (500,400),
);</code></pre><p>Transform initial x guess into z coordinates and plot</p><pre><code class="language-julia hljs">z0 = sqrtPdiag \ x0
scatter!(pd, [z0[1]], [z0[2]], color=:green, label = L&quot;z_0&quot;);</code></pre><p>Run GD</p><pre><code class="language-julia hljs">niter = 100
z = Array{Array{Float64,1},1}(undef, niter + 1)
z[1] = z0
for k in 1:niter
    z[k+1] = z[k] - ∇f̃diag(z[k])
end;</code></pre><p>Display iterates</p><pre><code class="language-julia hljs">plot!(pd, [z[k][1] for k in 1:niter], [z[k][2] for k in 1:niter],
    marker=:star, color=:blue, label = L&quot;z_k&quot;);</code></pre><p>Mark the minimum of the preconditioned cost function</p><pre><code class="language-julia hljs">scatter!(pd, [0], [0], label = L&quot;\hat{z}&quot;, color=:red,
    aspect_ratio = :equal, marker = :x)

# savefig(pd, &quot;precon1-pd.pdf&quot;)</code></pre><img src="611cd120.svg" alt="Example block output"/><pre><code class="language-julia hljs">prompt()</code></pre><p>Using the diagonal preconditioner did cause a coordinate change, but one less dramatic than did the ideal preconditioner. The contours in this new coordinate system are still ellipses, but they are slightly more circular. Using the diagonal preconditioner also resulted in eigenvalues of <span>$G$</span> that are smaller than when using (non-preconditioned) GD with optimal step size, and one can see that using the diagonal preconditioner appears to converge more quickly.</p><p>The following reports the ratio of the singular values of the three different <span>$A$</span> (or <span>$\tilde{A}$</span>) matrices used here. A value of 1 corresponds to circular cost function contours, and higher values correspond to more elliptical contours.</p><pre><code class="language-julia hljs">&quot;Ratio of singular values of A, A * sqrtPideal A * sqrtPdiag:&quot;

[
/(svdvals(A)...)
/(svdvals(A * sqrtPideal)...)
/(svdvals(A * sqrtPdiag)...)
]</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">3-element Vector{Float64}:
 3.3333333333333357
 1.0000000000000002
 2.121780582746997</code></pre><p>Here are the three plots displayed next to each other.</p><pre><code class="language-julia hljs">pp = plot(
    plot!(pu, title = &quot;GD&quot;),
    plot!(ph, title = &quot;Ideal&quot;),
    plot!(pd, title = &quot;Diagonal&quot;),
    size = (1900,470),
    layout=(1,3),
)

# savefig(pp, &quot;precon1-pp.pdf&quot;)</code></pre><img src="082cf88e.svg" alt="Example block output"/><h3 id="Reproducibility"><a class="docs-heading-anchor" href="#Reproducibility">Reproducibility</a><a id="Reproducibility-1"></a><a class="docs-heading-anchor-permalink" href="#Reproducibility" title="Permalink"></a></h3><p>This page was generated with the following version of Julia:</p><pre><code class="language-julia hljs">using InteractiveUtils: versioninfo
io = IOBuffer(); versioninfo(io); split(String(take!(io)), &#39;\n&#39;)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">11-element Vector{SubString{String}}:
 &quot;Julia Version 1.11.6&quot;
 &quot;Commit 9615af0f269 (2025-07-09 12:58 UTC)&quot;
 &quot;Build Info:&quot;
 &quot;  Official https://julialang.org/ release&quot;
 &quot;Platform Info:&quot;
 &quot;  OS: Linux (x86_64-linux-gnu)&quot;
 &quot;  CPU: 4 × AMD EPYC 7763 64-Core Processor&quot;
 &quot;  WORD_SIZE: 64&quot;
 &quot;  LLVM: libLLVM-16.0.6 (ORCJIT, znver3)&quot;
 &quot;Threads: 1 default, 0 interactive, 1 GC (on 4 virtual cores)&quot;
 &quot;&quot;</code></pre><p>And with the following package versions</p><pre><code class="language-julia hljs">import Pkg; Pkg.status()</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"><span class="sgr32"><span class="sgr1">Status</span></span> `~/work/book-la-demo/book-la-demo/docs/Project.toml`
  <span class="sgr90">[6e4b80f9] </span>BenchmarkTools v1.6.0
  <span class="sgr90">[aaaa29a8] </span>Clustering v0.15.8
  <span class="sgr90">[35d6a980] </span>ColorSchemes v3.30.0
<span class="sgr33">⌅</span> <span class="sgr90">[3da002f7] </span>ColorTypes v0.11.5
<span class="sgr32">⌃</span> <span class="sgr90">[c3611d14] </span>ColorVectorSpace v0.10.0
  <span class="sgr90">[717857b8] </span>DSP v0.8.4
  <span class="sgr90">[72c85766] </span>Demos v0.1.0 `~/work/book-la-demo/book-la-demo`
  <span class="sgr90">[e30172f5] </span>Documenter v1.14.1
  <span class="sgr90">[4f61f5a4] </span>FFTViews v0.3.2
  <span class="sgr90">[7a1cc6ca] </span>FFTW v1.9.0
  <span class="sgr90">[587475ba] </span>Flux v0.16.5
  <span class="sgr90">[a09fc81d] </span>ImageCore v0.10.5
  <span class="sgr90">[71a99df6] </span>ImagePhantoms v0.8.1
  <span class="sgr90">[b964fa9f] </span>LaTeXStrings v1.4.0
  <span class="sgr90">[7031d0ef] </span>LazyGrids v1.1.0
  <span class="sgr90">[599c1a8e] </span>LinearMapsAA v0.12.0
  <span class="sgr90">[98b081ad] </span>Literate v2.20.1
  <span class="sgr90">[7035ae7a] </span>MIRT v0.18.2
  <span class="sgr90">[170b2178] </span>MIRTjim v0.25.0
  <span class="sgr90">[eb30cadb] </span>MLDatasets v0.7.18
  <span class="sgr90">[efe261a4] </span>NFFT v0.13.7
  <span class="sgr90">[6ef6ca0d] </span>NMF v1.0.3
  <span class="sgr90">[15e1cf62] </span>NPZ v0.4.3
  <span class="sgr90">[0b1bfda6] </span>OneHotArrays v0.2.10
  <span class="sgr90">[429524aa] </span>Optim v1.13.2
  <span class="sgr90">[91a5bcdd] </span>Plots v1.40.19
  <span class="sgr90">[f27b6e38] </span>Polynomials v4.1.0
  <span class="sgr90">[2913bbd2] </span>StatsBase v0.34.6
  <span class="sgr90">[d6d074c3] </span>VideoIO v1.3.0
  <span class="sgr90">[b77e0a4c] </span>InteractiveUtils v1.11.0
  <span class="sgr90">[37e2e46d] </span>LinearAlgebra v1.11.0
  <span class="sgr90">[44cfe95a] </span>Pkg v1.11.0
  <span class="sgr90">[9a3f8284] </span>Random v1.11.0
<span class="sgr36"><span class="sgr1">Info</span></span> Packages marked with <span class="sgr32">⌃</span> and <span class="sgr33">⌅</span> have new versions available. Those with <span class="sgr32">⌃</span> may be upgradable, but those with <span class="sgr33">⌅</span> are restricted by compatibility constraints from upgrading. To see why use `status --outdated`</code></pre><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../logistic1/">« Logistic regression</a><a class="docs-footer-nextpage" href="../../10/foreback/">Video foreground/background separation »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Saturday 30 August 2025 19:29">Saturday 30 August 2025</span>. Using Julia version 1.11.6.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
