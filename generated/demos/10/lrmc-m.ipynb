{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Low-rank matrix completion: AltMin, ISTA, FISTA\n",
    "\n",
    "This example illustrates\n",
    "low-rank matrix completion\n",
    "via alternating projection, ISTA (PGM), and FISTA (FPGM),\n",
    "using the Julia language.\n",
    "\n",
    "(This approach is related to \"projection onto convex sets\" (POCS) methods,\n",
    "but the term \"POCS\" would be a misnomer here\n",
    "because the rank constraint is not a convex set.)\n",
    "\n",
    "History:\n",
    "* 2021-08-23 Julia 1.6.2\n",
    "* 2021-12-09 Julia 1.6.4 and use M not Ω\n",
    "* 2023-06-04 Julia 1.9.0 in Literate"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "Add the Julia packages used in this demo.\n",
    "Change `false` to `true` in the following code block\n",
    "if you are using any of the following packages for the first time."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "if false\n",
    "    import Pkg\n",
    "    Pkg.add([\n",
    "        \"InteractiveUtils\"\n",
    "        \"LaTeXStrings\"\n",
    "        \"LinearAlgebra\"\n",
    "        \"MIRTjim\"\n",
    "        \"Plots\"\n",
    "        \"Random\"\n",
    "        \"Statistics\"\n",
    "    ])\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tell Julia to use the following packages.\n",
    "Run `Pkg.add()` in the preceding code block first, if needed."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using InteractiveUtils: versioninfo\n",
    "using LinearAlgebra: svd, svdvals, rank, norm, Diagonal\n",
    "using LaTeXStrings\n",
    "using MIRTjim: jim, prompt\n",
    "using Plots: default, gui, plot, savefig, scatter, scatter!, xlabel!, xticks!\n",
    "using Plots.PlotMeasures: px\n",
    "using Random: seed!\n",
    "using Statistics: mean\n",
    "default(markersize=7, markerstrokecolor=:auto, label = \"\",\n",
    " tickfontsize = 10, legendfontsize = 18, labelfontsize = 16, titlefontsize = 18,\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following line is helpful when running this jl-file as a script;\n",
    "this way it will prompt user to hit a key after each image is displayed."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "isinteractive() && prompt(:prompt);\n",
    "jim(:prompt, true)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Latent matrix\n",
    "Make a matrix that has low rank"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "tmp = [\n",
    "    zeros(1,20);\n",
    "    0 1 0 0 0 0 1 0 0 0 1 1 1 1 0 1 1 1 1 0;\n",
    "    0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0;\n",
    "    0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0;\n",
    "    0 0 1 1 1 1 0 0 0 0 1 1 0 0 0 0 0 1 1 0;\n",
    "    zeros(1,20)\n",
    "]';\n",
    "rank(tmp)\n",
    "\n",
    "Xtrue = kron(10 .+ 80*tmp, ones(9,9))\n",
    "rtrue = rank(Xtrue)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "plots with consistent size"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "jim1 = (X ; kwargs...) -> jim(X; size = (600,300),\n",
    " leftmargin = 10px, rightmargin = 10px, kwargs...);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "and consistent display range"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "jimc = (X ; kwargs...) -> jim1(X; clim=(0,100), kwargs...);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "and with NRMSE label"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "nrmse = (Xh) -> round(norm(Xh - Xtrue) / norm(Xtrue) * 100, digits=1)\n",
    "args = (xaxis = false, yaxis = false, colorbar = :none) # book\n",
    "args = (;) # web\n",
    "jime = (X; kwargs...) -> jimc(X; xlabel = \"NRMSE = $(nrmse(X)) %\",\n",
    " args..., kwargs...,\n",
    ")\n",
    "title = latexstring(\"\\$\\\\mathbf{\\\\mathit{X}}\\$ : Latent image\")\n",
    "pt = jimc(Xtrue; title, xlabel = \" \", args...)\n",
    "# savefig(pt, \"mc_ap_x.pdf\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Noisy / incomplete data"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "seed!(0)\n",
    "M = rand(Float32, size(Xtrue)) .>= 0.75 # 75% missing\n",
    "Y = M .* (Xtrue + randn(size(Xtrue)));\n",
    "\n",
    "title = latexstring(\"\\$\\\\mathbf{\\\\mathit{Y}}\\$ : Corrupted image matrix\\n(missing pixels set to 0)\")\n",
    "py = jime(Y ; title)\n",
    "# savefig(py, \"mc_ap_y.pdf\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### What is rank(Y) ??\n",
    "* A 5-9\n",
    "* B 10-49\n",
    "* C 50-59\n",
    "* D 60-70\n",
    "* E 71-200\n",
    "\n",
    "rank(Y)\n",
    "svdvals(Y)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Show mask, count proportion of missing entries"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "frac_nonzero = count(M) / length(M)\n",
    "title = latexstring(\"\\$\\\\mathbf{\\\\mathit{M}}\\$ : Locations of observed entries\")\n",
    "pm = jim1(M; title, args...,\n",
    "    xlabel = \"sampled fraction = $(round(frac_nonzero * 100, digits=1))%\")\n",
    "# savefig(pm, \"mc_ap_m.pdf\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Low-rank approximation\n",
    "A simple low-rank approximation works poorly for missing data."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "r = 5\n",
    "U,s,V = svd(Y)\n",
    "Xr = U[:,1:r] * Diagonal(s[1:r]) * V[:,1:r]'\n",
    "title = latexstring(\"Rank $r approximation of data \\$\\\\mathbf{\\\\mathit{Y}}\\$\")\n",
    "pr = jime(Xr ; title)\n",
    "# savefig(pr, \"mc_ap_lr.pdf\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Alternating projection\n",
    "Alternating projection is an\n",
    "iterative method that alternates\n",
    "between projecting onto the set of rank-5 matrices\n",
    "and onto the set of matrices that match the data."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function projC(X, r::Int)\n",
    "    U,s,V = svd(X)\n",
    "    return U[:,1:r] * Diagonal(s[1:r]) * V[:,1:r]' # project onto \"𝒞\" &Cscr; U+1D49E\n",
    "end;\n",
    "\n",
    "function lrmc_alt(Y, r::Int, niter::Int)\n",
    "    Xr = copy(Y)\n",
    "    Xr[.!M] .= mean(Y[M]) # fill missing values with mean of other values\n",
    "    @show nrmse(Xr)\n",
    "    for iter in 1:niter\n",
    "        Xr = projC(Xr, r) # project onto \"𝒞\" &Cscr; U+1D49E\n",
    "        Xr[M] .= Y[M] # project onto \"𝒟\" &Dscr; U+1D49F\n",
    "        if 0 == iter % 40\n",
    "            @show nrmse(Xr)\n",
    "        end\n",
    "    end\n",
    "    return Xr\n",
    "end;\n",
    "\n",
    "niter_alt = 400\n",
    "r = 5\n",
    "Xr = lrmc_alt(Y, r, niter_alt)\n",
    "title = \"Alternating Projection at $niter_alt iterations\"\n",
    "pa = jime(Xr ; title)\n",
    "# savefig(pa, \"mc_ap_400.pdf\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### What is rank(Xr) here ??\n",
    "* A 5-9\n",
    "* B 10-49\n",
    "* C 50-59\n",
    "* D 60-70\n",
    "* E 71-200\n",
    "\n",
    "rank(Xr)\n",
    "svdvals(Xr)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run one more projection step onto the set of rank-r matrices"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Xfinal = projC(Xr, r)\n",
    "pf = jime(Xfinal ; title=\"Alternating Projection at $niter_alt iterations\")\n",
    "# savefig(pf, \"mc_ap_xh.pdf\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### What is rank(Xfinal) here ??\n",
    "* A 5-9\n",
    "* B 10-49\n",
    "* C 50-59\n",
    "* D 60-70\n",
    "* E 71-200\n",
    "\n",
    "rank(Xfinal)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot singular values"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "sr = svdvals(Xr)\n",
    "rankeff = s -> count(>(0.01*s[1]), s); # effective rank"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "ps = plot(title=\"singular values\",\n",
    " xaxis=(L\"k\", (1, minimum(size(Y))), [1, rankeff(sr), minimum(size(Y))]),\n",
    " yaxis=(L\"σ\",), labelfontsize = 18,\n",
    " leftmargin = 15px, bottommargin = 20px, size = (600,350), widen = true,\n",
    ")\n",
    "scatter!(ps, svdvals(Y), color=:red, label=\"Y (data)\", marker=:dtriangle)\n",
    "scatter!(ps, svdvals(Xtrue), color=:blue, label=\"Xtrue\", marker=:utriangle)\n",
    "pa = deepcopy(ps)\n",
    "scatter!(pa, sr, color=:green, label=\"Alt. Proj. output\")\n",
    "\n",
    "# savefig(pa, \"mc_ap_sv.pdf\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "prompt()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Nuclear norm approach\n",
    "Now we will try to recover the matrix\n",
    "using low-rank matrix completion\n",
    "with a nuclear-norm regularizer.\n",
    "\n",
    "The optimization problem we will solve is:\n",
    "$$\n",
    "\\arg\\min_{\\mathbf{\\mathit{X}}} \\frac{1}{2}\n",
    "‖ \\mathbf{\\mathit{M}} ⊙\n",
    " (\\mathbf{\\mathit{X}} - \\mathbf{\\mathit{Y}}) ‖_{\\mathrm{F}}^2\n",
    "+ \\beta ‖ \\mathbf{\\mathit{X}} ‖_*\n",
    "\\quad\\quad (\\text{NN-min})\n",
    "$$\n",
    "* $\\mathbf{\\mathit{Y}}$\n",
    "  is the zero-filled input data matrix\n",
    "* $\\mathbf{\\mathit{M}}$\n",
    "  is the binary sampling mask.\n",
    "\n",
    "Define cost function for optimization problem"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "nucnorm = (X) -> sum(svdvals(X)) # nuclear norm\n",
    "costfun1 = (X,beta) -> 0.5 * norm(M .* (X - Y))^2 + beta * nucnorm(X); # regularized cost"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q. The cost function above is (convex, strictly convex):\n",
    "* A: F,F\n",
    "* B: F,T\n",
    "* C: T,F\n",
    "* D: T,T"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define singular value soft thresholding (SVST) function"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "SVST = (X,beta) -> begin\n",
    "    U,s,V = svd(X) # see below\n",
    "    sthresh = max.(s .- beta, 0)\n",
    "    return U * Diagonal(sthresh) * V'\n",
    "end;"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q. Which svd is that?\n",
    "* A compact\n",
    "* B economy\n",
    "* C full\n",
    "* D none of these\n",
    "\n",
    "U,s,V = svd(Y)\n",
    "@show size(s), size(U), size(V)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ISTA\n",
    "\n",
    "The iterative soft-thresholding algorithm (ISTA)\n",
    "is an extension of gradient descent\n",
    "for (often convex) \"composite\" cost functions that look like\n",
    "$\\min_x f(x) + g(x)$\n",
    "where $f(x)$ is smooth and $g(x)$ is non-smooth.\n",
    "\n",
    "ISTA is also known as the\n",
    "[proximal gradient method (PGM)](http://www.stat.cmu.edu/~ryantibs/convexopt-S15/lectures/08-prox-grad.pdf).\n",
    "\n",
    "ISTA algorithm for solving (NN-min):\n",
    "* Initialize $\\mathbf{\\mathit{X}}_0 = \\mathbf{\\mathit{Y}}$ (zero-fill missing entries)\n",
    "* `for k=0,1,2,...`\n",
    "* $[\\mathbf{\\mathit{X}}_k]_{i,j} =\n",
    "  \\begin{cases}[\\mathbf{\\mathit{X}}_k]_{i,j} & \\text{if } (i,j) ∉ Ω\n",
    "  \\\\ [\\mathbf{\\mathit{Y}}]_{i,j} & \\text{if } (i,j) ∈ Ω \\end{cases}$\n",
    "  (Put back in known entries)\n",
    "\n",
    "* $\\mathbf{\\mathit{X}}_{k+1} = \\text{SVST}(\\mathbf{\\mathit{X}}_k, \\beta)$\n",
    "  (Singular value soft-thresholding)\n",
    "* `end`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "ISTA for matrix completion, using functions `SVST` and `costfun1`"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function lrmc_ista(Y, M, beta::Real, niter::Int)\n",
    "    X = copy(Y)\n",
    "    Xold = copy(X)\n",
    "    cost = zeros(niter+1)\n",
    "    cost[1] = costfun1(X, beta)\n",
    "    for k in 1:niter\n",
    "        @. X[M] = Y[M] # in place\n",
    "        X = SVST(X, beta)\n",
    "        cost[k+1] = costfun1(X, beta)\n",
    "    end\n",
    "    return X, cost\n",
    "end;"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Apply ISTA"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "niter = 1000\n",
    "beta = 0.8 # chosen by trial-and-error here\n",
    "xh_ista, cost_ista = lrmc_ista(Y, M, beta, niter)\n",
    "pp = jime(xh_ista ; title=\"ISTA result at $niter iterations\")\n",
    "\n",
    "# savefig(pp, \"mc-nuc-ista.pdf\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "That result is not good.\n",
    "What went wrong? Let's investigate.\n",
    "First, check if the ISTA solution is actually low-rank."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "sp = svdvals(xh_ista)\n",
    "psi = deepcopy(ps)\n",
    "scatter!(psi, sp, color=:orange, label=L\"\\hat{X} \\mathrm{(ISTA)}\")\n",
    "xticks!(psi, [1, rtrue, rank(Diagonal(sp)), minimum(size(Y))])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "prompt()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now check the cost function.\n",
    "It is decreasing monotonically, but quite slowly."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "scatter(cost_ista, color=:orange,\n",
    "    title=\"cost vs. iteration\",\n",
    "    xlabel=\"iteration\",\n",
    "    ylabel=\"cost function value\",\n",
    "    label=\"ISTA\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "prompt()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## FISTA\n",
    "\n",
    "The fast iterative soft-thresholding algorithm (FISTA)\n",
    "is a modification of ISTA that includes Nesterov acceleration\n",
    "for much faster convergence.\n",
    "Also known as the fast proximal gradient method (FPGM).\n",
    "\n",
    "Reference:\n",
    "- Beck, A. and Teboulle, M., 2009.\n",
    "  [A fast iterative shrinkage-thresholding algorithm for linear inverse problems](https://doi.org/10.1137/080716542).\n",
    "  SIAM journal on imaging sciences, 2(1):183-202.\n",
    "\n",
    "**FISTA algorithm for solving (NN-min)**\n",
    "* initialize matrices\n",
    "  $\\mathbf Z_0 = \\mathbf X_0 = \\mathbf Y$\n",
    "* `for k=0,1,2,...`\n",
    "* $[\\mathbf{Z}_k]_{i,j} =\n",
    "  \\begin{cases}[\\mathbf Z_k]_{i,j} & \\text{if}~(i,j) ∉ Ω\n",
    "  \\\\ [\\mathbf{Y}]_{i,j} & \\text{if}~(i,j) ∈ Ω \\end{cases}$\n",
    "  (Put back in known entries)\n",
    "\n",
    "* $\\mathbf{X}_{k+1} = \\text{SVST}(\\mathbf{Z}_k, \\beta)$\n",
    "* $t_{k+1} = \\frac{1 + \\sqrt{1+4t_k^2}}{2}$ (Nesterov step-size)\n",
    "* $\\mathbf{Z}_{k+1} = \\mathbf{X}_{k+1} + \\frac{t_k-1}{t_{k+1}} (\\mathbf{X}_{k+1} - \\mathbf{X}_k)$\n",
    "  (Momentum update)\n",
    "* `end`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "FISTA algorithm for low-rank matrix completion, using `SVST` and `costfun1`"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function lrmc_fista(Y, M, beta::Real, niter::Int)\n",
    "    X = copy(Y)\n",
    "    Z = copy(X)\n",
    "    Xold = copy(X)\n",
    "    told = 1\n",
    "    cost = zeros(niter+1)\n",
    "    cost[1] = costfun1(X, beta)\n",
    "    for k in 1:niter\n",
    "        @. Z[M] = Y[M]\n",
    "        X = SVST(Z, beta)\n",
    "        t = (1 + sqrt(1+4*told^2))/2\n",
    "        Z = X + ((told-1)/t) * (X - Xold)\n",
    "        Xold = copy(X)\n",
    "        told = t\n",
    "        cost[k+1] = costfun1(X, beta) # comment out to speed-up\n",
    "    end\n",
    "    return X, cost\n",
    "end;"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run FISTA"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "niter = 300\n",
    "xh_nn_fista, cost_fista = lrmc_fista(Y, M, beta, niter)\n",
    "p1 = jime(xh_nn_fista ; title=\"FISTA with nuclear norm at $niter iterations\")\n",
    "\n",
    "# savefig(p1, \"lrmc-nn-fs300.pdf\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot showing that FISTA converges much faster!\n",
    "[POGM](https://doi.org/10.1007/s10957-018-1287-4)\n",
    "would be even faster."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "plot(title=\"cost vs. iteration for NN regularizer\",\n",
    "    xlabel=\"iteration\", ylabel=\"cost function value\")\n",
    "scatter!(cost_ista, color=:orange, label=\"ISTA\")\n",
    "scatter!(cost_fista, color=:magenta, label=\"FISTA\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "prompt()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "See if the FISTA result is \"low rank\""
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "sf = svdvals(xh_nn_fista)\n",
    "rfista = rank(Diagonal(sf))\n",
    "rfista, rankeff(sf)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "psf = deepcopy(ps)\n",
    "scatter!(psf, sf, color=:magenta, label=\"Xh (output of FISTA)\")\n",
    "xticks!(psf, [1, rtrue, rfista, minimum(size(Y))])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "prompt()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Optional exercise: think about why $σ_1(Y) < σ_1(\\hat{X}) < σ_1(Xtrue)$\n",
    "* Optional: try ADMM too"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Your work goes below here\n",
    "The results below are place-holders that will be much improved\n",
    "when implemented properly."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "if true # replace these place-holder functions with your work\n",
    "    shrink_p_1_2(v, reg::Real) = v\n",
    "    lr_schatten(Y, reg::Real) = Y\n",
    "    fista_schatten(Y, M, reg::Real, niter::Int) = Y\n",
    "else # instructor version\n",
    "    mydir = ENV[\"hw551test\"] # change path\n",
    "    include(mydir * \"shrink_p_1_2.jl\") # 1D shrinker for |x|^(1/2), previous HW\n",
    "    include(mydir * \"lr_schatten.jl\")\n",
    "    include(mydir * \"fista_schatten.jl\")\n",
    "end;"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Apply FISTA for Schatten p=1/2"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "niter = 150\n",
    "reg_fs = 120\n",
    "xh_fs = fista_schatten(Y, M, reg_fs, niter)\n",
    "\n",
    "p2 = jime(xh_fs; title=\"FISTA for Schatten p=1/2, $niter iterations\")\n",
    "# savefig(\"schatten_complete_fs150_sp.pdf\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "See if the Schatten FISTA result is \"low rank\""
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "ss = svdvals(xh_fs)\n",
    "rank_schatten_fista = rank(Diagonal(ss))\n",
    "rank_schatten_fista, rankeff(ss)\n",
    "\n",
    "pss = deepcopy(ps)\n",
    "scatter!(pss, ss, color=:cyan, label=\"Xh (FISTA for Schatten)\")\n",
    "xticks!(pss, [1, rank_schatten_fista, minimum(size(Y))])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "prompt()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "error image for nuclear norm"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "p3 = jimc(xh_nn_fista - Xtrue; title = \"FISTA Nuclear Norm: Xh-X\", clim=(-80,80))\n",
    "# savefig(\"schatten_complete_fs300_nn_err.pdf\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "error image for schatten p=1/2"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "p4 = jimc(xh_fs - Xtrue; title = \"FISTA Schatten p=1/2 'Norm': Xh-X\", clim=(-80,80))\n",
    "# savefig(\"schatten_complete_fs150_sp_err.pdf\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.6"
  },
  "kernelspec": {
   "name": "julia-1.11",
   "display_name": "Julia 1.11.6",
   "language": "julia"
  }
 },
 "nbformat": 4
}
