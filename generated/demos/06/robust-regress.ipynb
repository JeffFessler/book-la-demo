{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Robust regression\n",
    "\n",
    "This example illustrates robust polynomial fitting\n",
    "with ℓₚ norm cost functions\n",
    "using the Julia language."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "Add the Julia packages used in this demo.\n",
    "Change `false` to `true` in the following code block\n",
    "if you are using any of the following packages for the first time."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "if false\n",
    "    import Pkg\n",
    "    Pkg.add([\n",
    "        \"InteractiveUtils\"\n",
    "        \"LaTeXStrings\"\n",
    "        \"LinearAlgebra\"\n",
    "        \"MIRTjim\"\n",
    "        \"Optim\"\n",
    "        \"Plots\"\n",
    "        \"Random\"\n",
    "    ])\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tell Julia to use the following packages.\n",
    "Run `Pkg.add()` in the preceding code block first, if needed."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using InteractiveUtils: versioninfo\n",
    "using LaTeXStrings\n",
    "using LinearAlgebra: norm\n",
    "using MIRTjim: prompt\n",
    "using Optim: optimize\n",
    "using Plots: default, plot, plot!, scatter, scatter!, savefig\n",
    "using Random: seed!\n",
    "default(); default(label=\"\", markerstrokecolor=:auto, widen=true, linewidth=2,\n",
    "    markersize = 6, tickfontsize=12, labelfontsize = 16, legendfontsize=14)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following line is helpful when running this jl-file as a script;\n",
    "this way it will prompt user to hit a key after each image is displayed."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "isinteractive() && prompt(:prompt);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simulated data from latent nonlinear function"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "s = (t) -> atan(4*(t-0.5)) # nonlinear function\n",
    "\n",
    "seed!(0) # seed rng\n",
    "M = 12 # how many data points\n",
    "tm = sort(rand(M)) # M random sample locations\n",
    "y = s.(tm) + 0.1 * randn(M) # noisy samples\n",
    "y[2] = 0.3 # simulate an outlier\n",
    "y[M-2] = -0.3 # another outlier\n",
    "\n",
    "t0 = range(0, 1, 101) # fine sampling for showing curve\n",
    "xaxis = (L\"t\", (0,1), 0:0.5:1)\n",
    "yaxis = (L\"y\", (-1.2, 1.7), -1:1)\n",
    "p0 = scatter(tm, y; color=:black, label=\"y (data with outliers)\",\n",
    " xaxis, yaxis)\n",
    "plot!(t0, s.(t0), color=:blue, label=\"s(t) : latent signal\", legend=:topleft)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "prompt()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Polynomial model"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "deg = 3 # polynomial degree\n",
    "Afun = (tt) -> [t.^i for t in tt, i in 0:deg] # matrix of monomials\n",
    "A = Afun(tm) # M × 4 matrix\n",
    "p1 = plot(title=\"Columns of matrix A\", xlabel=L\"t\", legend=:left)\n",
    "for i in 0:deg\n",
    "    plot!(p1, tm, A[:,i+1], marker=:circle, label = \"A[:,$(i+1)]\")\n",
    "end\n",
    "p1"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "prompt()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LS estimation\n",
    "This is not robust to the outliers."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "xls = A \\ y # backslash for LS solution using all M samples\n",
    "\n",
    "p2 = deepcopy(p0)\n",
    "plot!(p2, t0, Afun(t0)*xls, color=:magenta, label=\"LS fit\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "prompt()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Robust regression\n",
    "Using (differentiable) p-norm with $1 < p ≪ 2$\n",
    "avoids over-fitting the outlier data points."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "p = 1.1 # close to ℓ₁\n",
    "cost = x -> norm(A * x - y, p)\n",
    "x0 = xls # initial guess\n",
    "outp = optimize(cost, x0)\n",
    "xlp = outp.minimizer\n",
    "\n",
    "plot!(p2, t0, Afun(t0)*xlp, color=:green, line=:dash,\n",
    " label=\"Robust fit p=$p\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using 1-norm produces nearly the same results\n",
    "as using the p=1.1 norm."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "cost1 = x -> norm(A * x - y, 1) # ℓ₁\n",
    "out1 = optimize(cost1, x0)\n",
    "xl1 = out1.minimizer\n",
    "\n",
    "plot!(p2, t0, Afun(t0)*xl1, color=:orange, line=:dashdot,\n",
    " label=\"Robust fit p=1\")\n",
    "\n",
    "# savefig(p2, \"robust-regress.pdf\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.6"
  },
  "kernelspec": {
   "name": "julia-1.11",
   "display_name": "Julia 1.11.6",
   "language": "julia"
  }
 },
 "nbformat": 4
}
