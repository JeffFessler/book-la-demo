{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Classification with MLP\n",
    "\n",
    "This demo\n",
    "illustrates basic artificial NN training\n",
    "for a simple synthetic classification example\n",
    "with cross-entropy loss\n",
    "using Julia's `Flux` library.\n",
    "\n",
    "- Jeff Fessler, University of Michigan\n",
    "- 2018-10-18 Julia 1.0.1 original\n",
    "- 2024-02-26 Julia 1.10.1 update"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Packages needed here."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import Flux # Julia package for deep learning\n",
    "using Flux: Dense, Chain, relu, params, Adam, throttle, mse\n",
    "using Flux.Losses: logitcrossentropy\n",
    "using OneHotArrays: onehotbatch\n",
    "using InteractiveUtils: versioninfo\n",
    "using LaTeXStrings # pretty plot labels\n",
    "using MIRTjim: jim, prompt\n",
    "using Random: seed!, randperm\n",
    "using Plots: Plot, plot, plot!, scatter!, default, gui, savefig\n",
    "using Plots.PlotMeasures: px\n",
    "\n",
    "default(markersize=5, markerstrokecolor=:auto, label=\"\",\n",
    " legendfontsize=16, labelfontsize=16, tickfontsize=14)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following line is helpful when running this file as a script;\n",
    "this way it will prompt user to hit a key after each figure is displayed."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "isinteractive() ? jim(:prompt, true) : prompt(:draw);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate (synthetic) data\n",
    "\n",
    "This data is suitable for a \"hand crafted\" classifier.\n",
    "\n",
    "(The `Xvm` versions are vectors of matrices.)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Functions to simulate data that cannot be linearly separated"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function sim_ring(\n",
    "    n::Int, # number of points\n",
    "    r::Real, # radius of center of annulus center\n",
    "    σ::Real, # spread (annulus width)\n",
    ")\n",
    "    T = promote_type(eltype(r), eltype(σ))\n",
    "    rad = r .+ σ * randn(T, n)\n",
    "    ang = T(2π) * rand(T, n)\n",
    "    return Matrix([rad .* cos.(ang)  rad .* sin.(ang)]') # (2,n)\n",
    "end;\n",
    "\n",
    "K = 3 # classes\n",
    "nsim = (40, 80, 120) # how many in each class\n",
    "rsim = (0, 3, 6) # mean radii of each class\n",
    "dsim = (1.5, 4.5) # ideal decision boundaries\n",
    "function simdata(;\n",
    "    n = nsim,\n",
    "    r = rsim,\n",
    "    σ = Float32.((0.7, 0.5, 0.5)),\n",
    ")\n",
    "    Xvm = [sim_ring(n[k], r[k], σ[k]) for k in 1:K] # [K][n]\n",
    "    Yvm = [fill(k, 1, n[k]) for k in 1:K] # [K][n]\n",
    "    return (Xvm, Yvm)\n",
    "end;"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Scatter plot function"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function plot_data!(p, Xvm;\n",
    "    colors = (:blue, :red, :orange),\n",
    "    marks = (:circle, :star, :uptri),\n",
    ")\n",
    "    for k in 1:K\n",
    "        scatter!(p, Xvm[k][1,:], Xvm[k][2,:],\n",
    "           marker=marks[k], color=colors[k], label=\"class $k\")\n",
    "    end\n",
    "    tmp = range(0, 2π, 101)\n",
    "    for d in dsim\n",
    "        plot!(p, d * cos.(tmp), d * sin.(tmp), color=:gray)\n",
    "    end\n",
    "    return p\n",
    "end\n",
    "\n",
    "function plot_data(Xvm; kwargs...)\n",
    "    p = plot(\n",
    "     xaxis = (L\"x_1\", (-1,1).*8, -9:3:9),\n",
    "     yaxis = (L\"x_2\", (-1,1).*8, -9:3:9),\n",
    "     aspect_ratio = 1, size = (500,500);\n",
    "     kwargs...,\n",
    "    )\n",
    "    plot_data!(p, Xvm)\n",
    "end;"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training data"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "seed!(0)\n",
    "ntrain = nsim\n",
    "(Xvm_train, Yvm_train) = simdata(; n=ntrain)\n",
    "p0 = plot_data(Xvm_train)\n",
    "# savefig(p0, \"ring3-data.pdf\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "prompt()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Validation and testing data"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "(Xvm_valid, Yvm_valid) = simdata()\n",
    "(Xvm_test, Yvm_test) = simdata()\n",
    "\n",
    "p1 = plot_data(Xvm_valid; title=\"Validation\")\n",
    "p2 = plot_data(Xvm_test; title=\"Test\")\n",
    "\n",
    "p0t = plot!(deepcopy(p0); title=\"Train\")\n",
    "p3 = plot(p0t, p1, p2;\n",
    " leftmargin = 30px, bottommargin = 35px,\n",
    " size = (1600,500), layout=(1,3),\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "prompt()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hand-crafted classifier\n",
    "This data is not linearly separable,\n",
    "but a simple nonlinearity makes it so."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "lift1 = x -> [x; sqrt(sum(abs2, x))] # lift 1 feature vector\n",
    "lifter = xx -> mapslices(lift1, xx, dims=1) # apply to each data column\n",
    "Xvm_train_lift = lifter.(Xvm_train)\n",
    "Xm_train_lift = hcat(Xvm_train_lift...)\n",
    "pl_train = plot(Xm_train_lift[3,:], marker=:circle, yticks=(1:5)*1.5,\n",
    " xticks = cumsum([1; collect(ntrain)]),\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "prompt()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "So the levels 1.5 and 4.5 should work to separate classes.\n",
    "Try on the test data."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Xm_test_lift = hcat(lifter.(Xvm_test)...)\n",
    "lift_classifier = x -> x < dsim[1] ? 1 : x > dsim[2] ? 3 : 2\n",
    "class_test_lift = lift_classifier.(Xm_test_lift[3,:])\n",
    "test_lift_errors = count(class_test_lift .!= hcat(Yvm_test...)')\n",
    "@show test_lift_errors, size(Xm_test_lift, 2)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Permute the training data (just to be cautious)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Xm_train = hcat(Xvm_train...)\n",
    "Ym_train = hcat(Yvm_train...)\n",
    "perm = randperm(size(Xm_train,2))\n",
    "Xm_train = Xm_train[:,perm] # (2, sum(nsim))\n",
    "Ym_train = Ym_train[:,perm] # (1, sum(nsim))\n",
    "Xm_valid = hcat(Xvm_valid...)\n",
    "Ym_valid = hcat(Yvm_valid...)\n",
    "Xm_test = hcat(Xvm_test...)\n",
    "Ym_test = hcat(Yvm_test...);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train simple MLP model\n",
    "\n",
    "A\n",
    "[multilayer perceptron model]\n",
    "(https://en.wikipedia.org/wiki/Multilayer_perceptron)\n",
    "(MLP)\n",
    "consists of multiple fully connected layers.\n",
    "\n",
    "Train a basic NN model with 1 hidden layer;\n",
    "here using MSE loss just for illustration."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "if !@isdefined(state1)\n",
    "    nhidden = 10 # neurons in hidden layer\n",
    "    model = Chain(Dense(2, nhidden, relu), Dense(nhidden, 1))\n",
    "    loss3ms(model, x, y) = mse(model(x), y) # admittedly silly choice\n",
    "    iters = 2000\n",
    "    dataset = Base.Iterators.repeated((Xm_train, Ym_train), iters)\n",
    "    state1 = Flux.setup(Adam(), model)\n",
    "    Flux.train!(loss3ms, model, dataset, state1)\n",
    "end;\n",
    "\n",
    "scalar = y -> y[1]\n",
    "model1 = x -> scalar(model(x))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot results after training"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function display_decision_boundaries(\n",
    "    model;\n",
    "    x1range = range(-1f0,1f0,101)*8,\n",
    "    x2range = x1range,\n",
    "    kwargs...,\n",
    ")\n",
    "    D = [model1([x1;x2]) for x1 in x1range, x2 in x2range]\n",
    "    D = round.(D)\n",
    "    jim(x1range, x2range, D; color=:cividis,\n",
    "     xaxis = (L\"x_1\", (-1,1).*8, -9:3:9),\n",
    "     yaxis = (L\"x_2\", (-1,1).*8, -9:3:9),\n",
    "     aspect_ratio = 1, size = (500,500),\n",
    "    kwargs...)\n",
    "end;\n",
    "\n",
    "function display_decision_boundaries(model, Xvm; kwargs...)\n",
    "    p = display_decision_boundaries(model; kwargs...)\n",
    "    plot_data!(p, Xvm)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Examine classification accuracy"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "classacc(model, x, y::Number) = round(model1(x)) == y\n",
    "classacc(model, x, y::AbstractArray) = classacc(model, x, y[1])\n",
    "function classacc(Xm, Ym)\n",
    "    tmp = zip(eachcol(Xm), eachcol(Ym))\n",
    "    tmp = count(xy -> classacc(model, xy...), tmp)\n",
    "    tmp = tmp / size(Ym,2) * 100\n",
    "    return round(tmp, digits=3)\n",
    "end\n",
    "\n",
    "lossXYtrain = loss3ms(model, Xm_train, Ym_train)\n",
    "p4 = display_decision_boundaries(model, Xvm_train;\n",
    " title = \"Train: RMSE Loss = $(round(sqrt(lossXYtrain),digits=4)), \" *\n",
    " \"Class=$(classacc(Xm_train, Ym_train)) %\");\n",
    "lossXYtest = loss3ms(model, Xm_test, Ym_test)\n",
    "p5 = display_decision_boundaries(model, Xvm_test;\n",
    "     title = \"Test: RMSE Loss = $(round(sqrt(lossXYtest),digits=4)), \" *\n",
    "    \"Class=$(classacc(Xm_test, Ym_test)) %\");\n",
    "plot(p4, p5; size=(1000,500))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "prompt()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train while validating\n",
    "\n",
    "This time using cross-entropy loss,\n",
    "which makes more sense for a classification problem.\n",
    "\n",
    "Create a basic NN model with 1 hidden layer.\n",
    "This version evaluates performance every epoch\n",
    "for both the training data and validation data."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "if !@isdefined(model2) # || true\n",
    "    layer2 = Dense(2, nhidden, relu)\n",
    "    layer3 = Dense(nhidden, K)\n",
    "    model2 = Chain(layer2, layer3)\n",
    "    onehot1 = y -> reshape(onehotbatch(y, 1:K), K, :)\n",
    "    loss3ce(model, x, y) = logitcrossentropy(model(x), onehot1(y))\n",
    "\n",
    "    nouter = 80 # of outer iterations, for showing loss\n",
    "    losstrain = zeros(nouter+1)\n",
    "    lossvalid = zeros(nouter+1)\n",
    "\n",
    "    iters = 100 # inner iterations\n",
    "    losstrain[1] = loss3ce(model2, Xm_train, Ym_train)\n",
    "    lossvalid[1] = loss3ce(model2, Xm_valid, Ym_valid)\n",
    "\n",
    "    model2s = similar(Vector{Any}, nouter) # to checkpoint every outer iteration\n",
    "    for io in 1:nouter\n",
    "        # @show io\n",
    "        idataset = Base.Iterators.repeated((Xm_train, Ym_train), iters)\n",
    "        istate = Flux.setup(Adam(), model2)\n",
    "        Flux.train!(loss3ce, model2, idataset, istate)\n",
    "        losstrain[io+1] = loss3ce(model2, Xm_train, Ym_train)\n",
    "        lossvalid[io+1] = loss3ce(model2, Xm_valid, Ym_valid)\n",
    "        if (io ≤ 6) && false # set to true to make images\n",
    "            display_decision_boundaries(model2, Xvm_train)\n",
    "            plot!(title=\"$(io*iters) epochs\")\n",
    "            gui(); sleep(0.3)\n",
    "        end\n",
    "        model2s[io] = deepcopy(model2)\n",
    "    end\n",
    "end;"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Show loss vs epoch"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "ivalid = findfirst(>(0), diff(lossvalid))\n",
    "plot(xlabel=\"epoch/$(iters)\", yaxis=(\"CE loss\", (0,1.05*maximum(losstrain))))\n",
    "plot!(0:nouter, lossvalid, label=\"validation\", marker=:+, color=:violet)\n",
    "plot!(0:nouter, losstrain, label=\"training\", marker=:o, color=:green)\n",
    "plot!(xticks = [0, ivalid, nouter])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "prompt()\n",
    "\n",
    "model2v = model2s[ivalid]; # model at validation epoch\n",
    "lossf = (Xm,Ym) -> round(loss3ce(model2v, Xm, Ym), digits=4)\n",
    "loss_train = lossf(Xm_train, Ym_train)\n",
    "loss_valid = lossf(Xm_valid, Ym_valid)\n",
    "loss_test = lossf(Xm_test, Ym_test);\n",
    "\n",
    "p1 = display_decision_boundaries(model2v, Xvm_train;\n",
    " title=\"Train:\\nCE Loss = $loss_train\\n\" *\n",
    "    \"Class=$(classacc(Xm_train, Ym_train)) %\",\n",
    ")\n",
    "p2 = display_decision_boundaries(model2v, Xvm_valid;\n",
    " title=\"Valid:\\nCE Loss = $loss_valid\\n\" *\n",
    "    \"Class=$(classacc(Xm_valid, Ym_valid)) %\",\n",
    ")\n",
    "p3 = display_decision_boundaries(model2v, Xvm_test;\n",
    " title=\"Test:\\nCE Loss = $loss_test\\n\" *\n",
    "    \"Class=$(classacc(Xm_valid, Ym_valid)) %\",\n",
    ")\n",
    "p123 = plot(p1, p2, p3; size=(1500,500), layout=(1,3))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "prompt()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Show response of (trained) first hidden layer, at validation step"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "x1range = range(-1f0,1f0,31) * 6\n",
    "x2range = range(-1f0,1f0,33) * 6\n",
    "tmp = model2v.layers[1]\n",
    "layer2data = [tmp([x1;x2])[n] for x1 = x1range, x2 = x2range, n in 1:nhidden]\n",
    "\n",
    "pl = Array{Plot}(undef, nhidden)\n",
    "for n in 1:nhidden\n",
    "    ptmp = jim(x1range, x2range, layer2data[:,:,n], color=:cividis,\n",
    "        xtick=-6:6:6, ytick=-6:6:6,\n",
    "    )\n",
    "    if n == 7\n",
    "        plot!(ptmp, xlabel=L\"x_1\", ylabel=L\"x_2\")\n",
    "    end\n",
    "    pl[n] = ptmp\n",
    "end\n",
    "plot(pl[1:9]...)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "prompt()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reproducibility"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This page was generated with the following version of Julia:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "io = IOBuffer(); versioninfo(io); split(String(take!(io)), '\\n')"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "And with the following package versions"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import Pkg; Pkg.status()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.12.5"
  },
  "kernelspec": {
   "name": "julia-1.12",
   "display_name": "Julia 1.12.5",
   "language": "julia"
  }
 },
 "nbformat": 4
}